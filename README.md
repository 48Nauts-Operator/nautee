# ğŸ¤– Claude GitHub Assistant (V1)

A lightweight toolset to generate local code reviews using **Claude by Anthropic**.
[![Docs](https://img.shields.io/badge/ğŸ“„-View%20Documentation-blue)](https://github.com/48Nauts-Operator/nautee)
---

## âœ¨ Features

- ğŸ” Review individual files or full project folders
- ğŸ§  Uses Claude to generate clean, structured Markdown feedback
- ğŸ—‚ï¸ Saves all reviews into the `output/` directory
- âœ… Supports reviewing Git diffs with zero config

---

## ğŸ› ï¸ Setup

1. Copy `.env.sample` to `.env` and add your Claude API key:

```bash
cp .env.sample .env

	2.	Install dependencies:

pip install anthropic python-dotenv

No requirements.txt is needed yet â€” you can add one later if needed.

â¸»

ğŸš€ Usage

ğŸ”¹ Review specific files

python tools/claude_review.py ../yourrepo/file1.py ../yourrepo/file2.py

ğŸ”¹ Review current Git diff (staged changes)

python tools/claude_review.py

Automatically detects git diff --staged

ğŸ”¹ Review an entire folder

python tools/claude_folder_review.py ../yourrepo/

Skips test files and __init__.py by default

â¸»

ğŸ“ Output

All reviews are saved as Markdown files in the output/ folder:
	â€¢	Named and structured for easy reference
	â€¢	Works with Markdown renderers and editors

â¸»

ğŸ” Local & Secure
	â€¢	Runs entirely locally
	â€¢	No data is stored externally
	â€¢	Your Claude API key stays in your .env file

â¸»

ğŸ›£ï¸ Roadmap (V2+ Preview)
	â€¢	Add Vector DB + Postgres for issue tracking
	â€¢	Dashboards to monitor bad patterns
	â€¢	LiteLLM support for multi-LLM agents
	â€¢	Integration with Cursor, ClickUp, and Jira
	â€¢	Dev behavior analytics + pattern database

â¸»

ğŸ§‘â€ğŸ’» Author

Designed for developers who want instant, intelligent feedback â€” without giving up local control.
