<!-- Auto-generated by Claude on 2025-06-08 01:51 -->

# Claude Folder Reviewer Documentation

## Overview

The **Claude Folder Reviewer** is a Python script that automates code review processes by scanning a directory for source files and leveraging Anthropic's Claude AI to provide comprehensive structural insights. The tool is designed to help developers identify code organization issues, potential bugs, architectural weaknesses, and opportunities for improvement.

## Purpose

This script serves as an automated code review assistant that:
- Scans directories recursively for source code files
- Batches multiple files into a single analysis request
- Uses Claude AI to generate detailed code insights in Markdown format
- Provides visual progress tracking during file processing
- Outputs timestamped review reports for documentation

## Key Features

- **Multi-language support**: Handles Python, JavaScript, TypeScript, JSX, and TSX files
- **Progress visualization**: Real-time progress bar with ETA calculations
- **Error handling**: Graceful handling of file read errors and API failures
- **Automated output**: Generates timestamped Markdown reports
- **Configurable**: Uses environment variables for API configuration

## Functions

### `render_progress(current: int, total: int, width: int = 30) -> str`

Creates a visual progress bar for tracking file processing status.

**Parameters:**
- `current`: Number of files processed so far
- `total`: Total number of files to process
- `width`: Character width of the progress bar (default: 30)

**Returns:** Formatted string with visual progress bar and percentage

```python
# Example output: [████████████████████----------] 67%
```

### `estimate_valid_files(folder: str, valid_exts: tuple) -> list`

Recursively searches a directory structure for source code files with specified extensions.

**Parameters:**
- `folder`: Root directory path to search
- `valid_exts`: Tuple of acceptable file extensions

**Returns:** List of full file paths matching the criteria

### `main()`

The primary execution function that orchestrates the entire review process:

1. **Environment Setup**: Loads API credentials and configuration
2. **File Discovery**: Scans the target directory for valid source files
3. **Content Aggregation**: Reads and combines all source files
4. **AI Analysis**: Sends batched content to Claude for review
5. **Report Generation**: Saves the analysis results to a timestamped file

## Configuration

### Environment Variables

Create a `.env` file in the script directory with the following variables:

```env
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514
```

### Supported File Extensions

The script currently processes files with these extensions:
- `.py` (Python)
- `.js` (JavaScript)
- `.ts` (TypeScript)
- `.tsx` (TypeScript React)
- `.jsx` (JavaScript React)

## Usage

### Basic Usage

```bash
python claude_folder_reviewer.py
```
*Reviews the default `../137docs` directory*

### Custom Directory

```bash
python claude_folder_reviewer.py /path/to/your/project
```

### Output

The script generates reports in the `output/` directory with filenames like:
```
output/folder_review_2024-01-15T14-30-25.md
```

## Dependencies

Install required packages:

```bash
pip install anthropic python-dotenv
```

## Notes and Suggestions

### Performance Considerations
- **Large codebases**: Be mindful of Claude's token limits when processing very large projects
- **API costs**: Each review consumes API tokens; consider batching strategies for frequent use

### Customization Opportunities
- **File filters**: Extend `valid_exts` to include additional file types
- **Review focus**: Modify the prompt to emphasize specific aspects (security, performance, etc.)
- **Output formats**: Adapt the output to generate different report formats

### Error Handling
- The script continues processing even if individual files fail to read
- API errors are caught and reported without crashing the entire process
- Missing directories or empty folders are handled gracefully

### Best Practices
- **API key security**: Never commit `.env` files to version control
- **Regular reviews**: Use this tool as part of your development workflow
- **Complementary tool**: This supplements, but doesn't replace, human code review

## Limitations

- **Context window**: Very large codebases may exceed Claude's context limits
- **Language specificity**: Analysis quality may vary across different programming languages
- **Static analysis only**: Cannot identify runtime-specific issues or performance bottlenecks

## Future Enhancements

Consider implementing:
- Configuration file support for custom settings
- Integration with Git to review only changed files
- Support for additional output formats (JSON, HTML)
- Parallel processing for improved performance on large codebases