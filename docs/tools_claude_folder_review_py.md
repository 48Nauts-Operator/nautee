<!-- Auto-generated by Claude on 2025-06-23 06:38 -->

# Claude Folder Reviewer Documentation

## Overview

The **Claude Folder Reviewer** is a Python script that automates code review processes by scanning source code folders and leveraging Anthropic's Claude AI to generate comprehensive code analysis reports. The tool aggregates all source files in a directory, sends them to Claude for analysis, and outputs structured insights in Markdown format.

## Purpose

This script is designed to help developers and teams:
- Get automated code reviews for entire codebases
- Identify structural issues and architectural weaknesses
- Receive suggestions for code organization improvements
- Detect common bug patterns across multiple files
- Generate documentation-ready review reports

## Features

- **Recursive File Scanning**: Automatically discovers source files in nested directories
- **Progress Tracking**: Visual progress bar with ETA estimation
- **Multiple Language Support**: Supports Python, JavaScript, TypeScript, JSX, and TSX files
- **AI-Powered Analysis**: Uses Claude AI for intelligent code review
- **Markdown Output**: Generates well-formatted review reports

## Requirements

### Dependencies
```python
import os
import sys
import anthropic
from dotenv import load_dotenv
from datetime import datetime
import time
```

### Environment Variables
- `ANTHROPIC_API_KEY`: Your Anthropic API key (required)
- `ANTHROPIC_MODEL`: Claude model to use (optional, defaults to "claude-sonnet-4-20250514")

### Installation
```bash
pip install anthropic python-dotenv
```

## Key Functions

### `render_progress(current: int, total: int, width: int = 30) -> str`

Generates a visual progress bar for tracking file processing.

**Parameters:**
- `current`: Current number of processed files
- `total`: Total number of files to process
- `width`: Character width of the progress bar (default: 30)

**Returns:** Formatted progress bar string with percentage

**Example Output:**
```
[██████████████████████████████] 100%
```

### `estimate_valid_files(folder: str, valid_exts: tuple) -> list`

Recursively scans a directory for source files with valid extensions.

**Parameters:**
- `folder`: Root directory path to scan
- `valid_exts`: Tuple of acceptable file extensions

**Returns:** List of full file paths matching the criteria

**Supported Extensions:**
- `.py` (Python)
- `.js` (JavaScript)
- `.ts` (TypeScript)
- `.tsx` (TypeScript JSX)
- `.jsx` (JavaScript JSX)

### `main()`

The primary execution function that orchestrates the entire review process:

1. **Environment Setup**: Loads environment variables and initializes Claude client
2. **File Discovery**: Scans target folder for valid source files
3. **Content Aggregation**: Reads and combines all source files into a single prompt
4. **AI Analysis**: Sends combined content to Claude for review
5. **Report Generation**: Saves the analysis to a timestamped Markdown file

## Usage

### Basic Usage
```bash
python claude_folder_reviewer.py
```
*Uses default folder: `../137docs`*

### Custom Folder
```bash
python claude_folder_reviewer.py /path/to/your/project
```

### Setup
1. Create a `.env` file with your Anthropic API key:
   ```
   ANTHROPIC_API_KEY=your_api_key_here
   ANTHROPIC_MODEL=claude-sonnet-4-20250514
   ```

2. Run the script from your terminal

## Output

The script generates:
- **Progress Updates**: Real-time processing status with ETA
- **Review Report**: Markdown file saved to `output/folder_review_YYYY-MM-DDTHH-MM-SS.md`
- **File Summary**: List of all reviewed files

### Sample Output Structure
```
output/
└── folder_review_2024-01-15T14-30-45.md
```

## Review Focus Areas

The Claude AI analysis focuses on:
- **Code Organization**: Structure and modularity assessment
- **Bug Patterns**: Common error-prone code patterns
- **Architecture Weaknesses**: Design flaws and improvement opportunities
- **Modularization Suggestions**: Recommendations for better code separation
- **Clarity Improvements**: Suggestions for more readable code

## Error Handling

The script includes robust error handling for:
- Missing or invalid API keys
- File read permissions issues
- Claude API communication errors
- Empty directories or no valid files found

## Notes and Suggestions

### Performance Considerations
- Large codebases may take significant time to process
- Claude API has token limits; very large codebases might need chunking
- Consider breaking down massive projects into smaller review sessions

### Best Practices
- Review the generated reports thoroughly
- Use the insights as starting points for deeper code analysis
- Combine automated reviews with human code review processes
- Regularly update the Claude model version for improved analysis quality

### Limitations
- Token limits may truncate very large codebases
- AI analysis quality depends on code complexity and clarity
- Some domain-specific issues may not be detected
- False positives in bug pattern detection are possible

### Potential Improvements
- Add support for more programming languages
- Implement file size filtering to avoid token limit issues
- Add configuration file support for custom review criteria
- Include code metrics and complexity analysis