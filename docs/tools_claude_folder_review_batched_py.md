<!-- Auto-generated by Claude on 2025-06-22 08:25 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review system that leverages Anthropic's Claude AI to analyze source code files in batches. The tool recursively scans a specified folder, groups files into token-optimized batches, and generates comprehensive Markdown reviews focusing on code organization, bug patterns, architecture weaknesses, and improvement suggestions.

## Purpose

- **Automated Code Review**: Performs AI-powered analysis of entire codebases
- **Batch Processing**: Efficiently handles large projects by splitting files into manageable chunks
- **Token Optimization**: Respects API token limits (~10k tokens per batch)
- **Documentation Generation**: Creates structured Markdown reports for each batch

## Key Features

- Recursive folder scanning with file type filtering
- Intelligent test file exclusion
- Token estimation and batch management
- Error handling for file reading and API calls
- Timestamped output with organized file structure

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from review based on naming patterns.

**Parameters:**
- `filename` (str): The file path to evaluate

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Exclusion Criteria:**
- Files containing "test" in the name
- Files starting with "test_"
- Files in directories containing "test"

```python
# Examples of excluded files:
# - test_utils.py
# - /tests/integration.py
# - MyTestFile.js
```

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API usage planning.

**Parameters:**
- `text` (str): Source code content

**Returns:**
- `int`: Estimated token count (uses 4 characters â‰ˆ 1 token ratio)

**Note:** This is a simplified estimation. Actual token counts may vary based on Claude's tokenization.

### `main()`

The primary execution function that orchestrates the entire review process.

**Workflow:**
1. **Environment Setup**: Loads API keys and configuration
2. **File Discovery**: Scans folder for valid source files
3. **Token Batching**: Groups files into API-friendly chunks
4. **Review Generation**: Processes each batch through Claude API
5. **Output Creation**: Saves formatted Markdown reviews

## Configuration

### Environment Variables

```bash
# Required
ANTHROPIC_API_KEY=your_api_key_here

# Optional
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Default model
```

### Supported File Types

- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other**: `.go`, `.java`

## Usage

### Basic Usage

```bash
python claude_folder_review.py /path/to/your/project
```

### Default Behavior

```bash
python claude_folder_review.py
# Reviews '../137docs' folder by default
```

## Output Structure

```
docs/folder_review/
â”œâ”€â”€ folder_review_batch_01.md
â”œâ”€â”€ folder_review_batch_02.md
â””â”€â”€ folder_review_batch_03.md
```

### Sample Output Format

```markdown
# ðŸ“¦ Folder Review Batch 1

_Last updated: 2024-01-15 14:30_

## Code Organization
- Well-structured module hierarchy
- Clear separation of concerns

## Bug Patterns
- Missing error handling in API calls
- Potential memory leaks in loops

## Architecture Weaknesses
- Tight coupling between components
- Lack of dependency injection

## Suggestions
- Implement factory patterns
- Add comprehensive logging
```

## Performance Considerations

- **Token Limit**: Each batch is capped at ~10,000 tokens
- **Rate Limiting**: No built-in rate limiting (consider adding delays for large projects)
- **Memory Usage**: Files are read sequentially to minimize memory footprint

## Error Handling

The script includes robust error handling for:
- **File Reading Errors**: Logs errors and continues processing
- **API Failures**: Reports batch-specific errors without stopping execution
- **Missing Dependencies**: Clear error messages for setup issues

## Suggestions for Enhancement

### ðŸ”§ Potential Improvements

1. **Rate Limiting**: Add configurable delays between API calls
2. **Resumption**: Implement checkpoint system for interrupted reviews
3. **Custom Filters**: Allow user-defined file exclusion patterns
4. **Output Formats**: Support for HTML, PDF, or JSON outputs
5. **Metrics**: Add code complexity and quality metrics
6. **Integration**: Git hook integration for automated reviews

### ðŸš¨ Known Limitations

- Token estimation is approximate
- No support for binary files
- Limited to specified file extensions
- Requires stable internet connection for API calls

## Dependencies

```python
anthropic>=0.3.0
python-dotenv>=0.19.0
```

## Setup Instructions

1. **Install Dependencies**:
   ```bash
   pip install anthropic python-dotenv
   ```

2. **Configure Environment**:
   ```bash
   echo "ANTHROPIC_API_KEY=your_key_here" > .env
   ```

3. **Run Review**:
   ```bash
   python claude_folder_review.py /path/to/project
   ```

This tool is ideal for development teams seeking automated code quality insights and architectural guidance for their projects.