<!-- Auto-generated by Claude on 2025-06-21 21:17 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review solution that recursively analyzes source code files in a folder using Anthropic's Claude AI model. The script intelligently batches files to stay within token limits and generates comprehensive markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverages Claude AI to provide senior-level code review insights
- **Batch Processing**: Handles large codebases by splitting files into manageable chunks (~10k tokens each)
- **Documentation Generation**: Creates structured markdown reports for each batch of reviewed files
- **Selective Analysis**: Focuses on production code by excluding test files and irrelevant file types

## Key Features

### File Discovery & Filtering
- Recursively scans directories for source code files
- Supports multiple programming languages and file types
- Automatically excludes test files and directories
- Configurable file extension filtering

### Intelligent Batching
- Estimates token usage to prevent API limit violations
- Groups files into batches of approximately 10,000 tokens
- Preserves file context within batches for better analysis

### AI-Powered Analysis
- Uses Claude AI for comprehensive code review
- Focuses on architecture, organization, and bug patterns
- Provides actionable suggestions for improvement

## Important Functions

### `is_excluded(filename: str) -> bool`
Determines whether a file should be excluded from review based on naming patterns.

**Parameters:**
- `filename`: Full path or name of the file to check

**Returns:**
- `True` if the file should be excluded (test files), `False` otherwise

**Usage:**
```python
if not is_excluded(full_path):
    files.append(full_path)
```

### `estimate_tokens(text: str) -> int`
Provides a rough estimate of token count for API usage planning.

**Parameters:**
- `text`: Source code content to estimate

**Returns:**
- Estimated token count (using 4 characters per token approximation)

**Note:** This is a simple estimation method. For production use, consider using more accurate tokenization libraries.

## Configuration

### Environment Variables
The script requires the following environment variables (typically stored in a `.env` file):

```env
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, has default
```

### Supported File Extensions
```python
valid_exts = (".py", ".js", ".ts", ".tsx", ".jsx", ".html", ".css", ".json", ".go", ".java", ".yaml", ".yml")
```

## Usage

### Basic Usage
```bash
python claude_folder_review.py /path/to/your/codebase
```

### Default Behavior
If no folder is specified, it defaults to reviewing `../137docs`:
```bash
python claude_folder_review.py
```

## Output Structure

The script generates markdown files in the `docs/folder_review/` directory:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

Each batch file contains:
- Batch number and metadata
- Timestamp of generation
- Detailed AI-generated review focusing on:
  - Code organization
  - Bug patterns
  - Architecture weaknesses
  - Modularization suggestions

## Error Handling

The script includes robust error handling for:
- **File Reading Errors**: Continues processing other files if one fails
- **API Errors**: Reports Claude API issues per batch
- **Missing Files**: Validates folder existence and file discovery

## Performance Considerations

- **Token Limits**: Respects Claude's token limitations through intelligent batching
- **API Rate Limiting**: Processes batches sequentially to avoid rate limits
- **Memory Usage**: Reads files individually to minimize memory footprint
- **Progress Tracking**: Provides real-time feedback on processing status

## Suggestions for Improvement

### 1. Enhanced Token Estimation
Consider using the `tiktoken` library for more accurate token counting:
```python
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4")
def estimate_tokens(text: str) -> int:
    return len(encoding.encode(text))
```

### 2. Parallel Processing
For large codebases, implement concurrent batch processing with rate limiting.

### 3. Configuration File
Add support for a configuration file to customize:
- File extensions
- Exclusion patterns
- Review focus areas
- Output formats

### 4. Incremental Reviews
Implement file change detection to only review modified files in subsequent runs.

### 5. Integration Options
Consider adding support for:
- Git integration for commit-based reviews
- CI/CD pipeline integration
- Multiple output formats (HTML, PDF)

## Dependencies

```python
anthropic  # Claude AI API client
python-dotenv  # Environment variable management
```

Install with:
```bash
pip install anthropic python-dotenv
```

## Notes

- Ensure your Anthropic API key has sufficient credits for large codebases
- Review generated markdown files may require manual editing for specific formatting needs
- The script creates output directories automatically
- Test files are intentionally excluded to focus on production code quality