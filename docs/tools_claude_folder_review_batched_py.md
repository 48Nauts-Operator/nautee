<!-- Auto-generated by Claude on 2025-06-01 18:24 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review solution that uses Anthropic's Claude AI to analyze source code files in batches. It recursively scans a specified folder, groups files into token-limited batches, and generates comprehensive Markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverage Claude AI to perform systematic code reviews
- **Batch Processing**: Handle large codebases by splitting them into manageable chunks
- **Documentation Generation**: Create structured Markdown reports for each review batch
- **Token Management**: Automatically manage API token limits (~10k tokens per batch)

## Key Features

- Recursive folder scanning with file type filtering
- Intelligent batching based on token estimates
- Test file exclusion
- Structured Markdown output with timestamps
- Error handling and progress tracking

## Installation & Setup

### Prerequisites

```bash
pip install anthropic python-dotenv
```

### Environment Configuration

Create a `.env` file with:

```env
ANTHROPIC_API_KEY=your_claude_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, has default
```

## Usage

### Basic Usage

```bash
python claude_folder_review.py [folder_path]
```

### Examples

```bash
# Review current directory
python claude_folder_review.py .

# Review specific folder
python claude_folder_review.py /path/to/project

# Use default folder (../137docs)
python claude_folder_review.py
```

## Core Functions

### `is_excluded(filename: str) -> bool`

Determines if a file should be excluded from review based on naming patterns.

**Parameters:**
- `filename`: Path or name of the file to check

**Returns:**
- `True` if file should be excluded (contains "test" patterns)
- `False` if file should be included

**Exclusion Patterns:**
- Files with "test" in name (case-insensitive)
- Files starting with "test_"
- Files in "/test" or "\\test" directories

### `estimate_tokens(text: str) -> int`

Provides a rough estimate of token count for API usage planning.

**Parameters:**
- `text`: Source code content

**Returns:**
- Estimated token count (using 4 characters ≈ 1 token ratio)

**Note:** This is a simplified estimation. For production use, consider using a proper tokenizer.

### `main()`

The primary orchestration function that handles:

1. **Environment Setup**: Loads API credentials and configuration
2. **File Discovery**: Recursively finds valid source files
3. **Batch Creation**: Groups files by estimated token count
4. **API Processing**: Sends batches to Claude for review
5. **Output Generation**: Saves Markdown reviews with timestamps

## Supported File Types

The script processes files with the following extensions:

- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other Languages**: `.go`, `.java`

## Output Structure

Reviews are saved to `docs/folder_review/` with the naming pattern:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_XX.md
```

Each file contains:
- Header with batch number
- Timestamp of generation
- Claude's structured review focusing on:
  - Code organization
  - Bug patterns
  - Architecture weaknesses
  - Modularization suggestions

## Configuration Options

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ANTHROPIC_API_KEY` | Required | Your Claude API key |
| `ANTHROPIC_MODEL` | `claude-sonnet-4-20250514` | Claude model to use |

### Script Constants

| Constant | Value | Description |
|----------|-------|-------------|
| `MAX_TOKENS` | 10000 | Maximum tokens per batch |
| `output_root` | `docs/folder_review` | Output directory |
| `folder` | `../137docs` | Default input folder |

## Error Handling

The script includes robust error handling for:

- **File Reading Errors**: Individual file failures don't stop processing
- **API Errors**: Network or API issues are logged with batch information
- **Missing Files**: Validates folder exists and contains valid files
- **Environment Issues**: Checks for required API keys

## Performance Considerations

- **Rate Limiting**: No built-in rate limiting - consider adding delays for large batches
- **Token Estimation**: Uses simple character-based estimation
- **Memory Usage**: Loads entire files into memory - may need optimization for very large files

## Suggestions for Enhancement

### Immediate Improvements

1. **Add Rate Limiting**: Implement delays between API calls
2. **Better Token Estimation**: Use proper tokenizer library
3. **Configuration File**: Support external config files
4. **Progress Bar**: Add visual progress indicators

### Advanced Features

1. **Incremental Reviews**: Only review changed files
2. **Custom Prompts**: Allow customizable review criteria
3. **Multiple Output Formats**: Support JSON, HTML outputs
4. **Parallel Processing**: Concurrent API calls with proper rate limiting

### Example Enhancement

```python
# Add rate limiting
import time

# In main() loop
time.sleep(1)  # 1 second between requests
```

## Troubleshooting

### Common Issues

1. **No files found**: Check file extensions and exclusion patterns
2. **API errors**: Verify API key and network connectivity
3. **Token limits**: Reduce `MAX_TOKENS` if hitting API limits
4. **Permission errors**: Ensure write access to output directory

### Debug Mode

Consider adding verbose logging:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```