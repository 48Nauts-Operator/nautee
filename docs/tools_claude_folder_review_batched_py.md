<!-- Auto-generated by Claude on 2025-06-01 19:15 -->

# Claude Folder Review (Batched) Documentation

## Overview

This script provides an automated code review solution that recursively analyzes source code files in a folder using Anthropic's Claude AI model. The tool intelligently splits large codebases into manageable batches and generates comprehensive markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverages Claude AI to perform senior-level code reviews
- **Batch Processing**: Handles large codebases by splitting them into ~10k token chunks
- **Documentation Generation**: Creates organized markdown reports for easy consumption
- **Multi-language Support**: Supports various programming languages and file types

## Key Features

- Token-aware batching to stay within API limits
- Automatic exclusion of test files
- Support for multiple file extensions
- Timestamped output files
- Error handling and progress tracking

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from the review process.

**Parameters:**
- `filename` (str): The file path to check

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Exclusion Criteria:**
- Files containing "test" in the name (case-insensitive)
- Files starting with "test_"
- Files in directories containing "test"

```python
# Examples of excluded files:
# - test_utils.py
# - /tests/integration.js
# - TestComponent.tsx
```

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API planning.

**Parameters:**
- `text` (str): The source content to analyze

**Returns:**
- `int`: Estimated token count (uses 4 characters per token approximation)

**Note:** This is a simplified estimation. For production use, consider using more accurate tokenization libraries.

### `main()`

The primary function that orchestrates the entire review process.

**Workflow:**
1. **Setup**: Loads environment variables and initializes Claude client
2. **File Discovery**: Recursively finds valid source files
3. **Token Batching**: Groups files into batches under the token limit
4. **Review Processing**: Sends batches to Claude for analysis
5. **Output Generation**: Saves markdown reviews to disk

## Configuration

### Environment Variables

Create a `.env` file with the following variables:

```env
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, has default
```

### Supported File Extensions

The script processes files with these extensions:

- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other Languages**: `.go`, `.java`

## Usage

### Basic Usage

```bash
python claude_folder_review.py /path/to/your/codebase
```

### Default Folder

If no folder is specified, it defaults to `../137docs`:

```bash
python claude_folder_review.py
```

## Output

### File Structure

Reviews are saved in the `docs/folder_review/` directory:

```
docs/
└── folder_review/
    ├── folder_review_batch_01.md
    ├── folder_review_batch_02.md
    └── folder_review_batch_03.md
```

### Review Content

Each batch file contains:

- **Header**: Batch number and timestamp
- **Code Analysis**: Architecture insights and recommendations
- **Bug Patterns**: Potential issues identified
- **Suggestions**: Modularization and clarity improvements

## Configuration Options

### Token Limit

```python
MAX_TOKENS = 10000  # Adjust based on your needs and API limits
```

### Output Directory

```python
output_root = "docs/folder_review"  # Customize output location
```

## Error Handling

The script includes robust error handling for:

- **File Reading Errors**: Continues processing other files
- **API Errors**: Reports issues but continues with remaining batches
- **Missing Files**: Exits gracefully with helpful messages

## Performance Considerations

- **API Rate Limits**: Consider adding delays between requests for large codebases
- **Token Estimation**: The current estimation is approximate; consider more precise tokenization
- **Memory Usage**: Large files are loaded into memory; monitor usage for very large codebases

## Suggestions for Enhancement

### 1. Add Rate Limiting

```python
import time

# Add between API calls
time.sleep(1)  # 1 second delay
```

### 2. Improve Token Estimation

Consider using tiktoken or similar libraries for more accurate token counting.

### 3. Add Configuration File

Create a `config.yaml` for easier customization:

```yaml
max_tokens: 10000
output_directory: "docs/reviews"
excluded_patterns:
  - "test"
  - "spec"
  - "__pycache__"
```

### 4. Add Progress Bar

```python
from tqdm import tqdm

for i, batch in enumerate(tqdm(batches, desc="Processing batches")):
    # ... processing code
```

## Dependencies

Install required packages:

```bash
pip install anthropic python-dotenv
```

## Security Notes

- Store API keys securely in environment variables
- Avoid committing `.env` files to version control
- Consider using secret management tools for production environments