<!-- Auto-generated by Claude on 2025-06-22 06:28 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review system that leverages Claude AI to analyze source code files in batches. It recursively scans a specified folder, processes source files in manageable chunks, and generates comprehensive Markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Uses Claude AI to perform intelligent code analysis
- **Batch Processing**: Handles large codebases by splitting files into ~10k token chunks
- **Multi-language Support**: Reviews various programming languages and file types
- **Documentation Generation**: Outputs structured Markdown reports for each batch

## Key Features

- Recursive folder scanning with file filtering
- Token-based batching to respect API limits
- Exclusion of test files to focus on core functionality
- Timestamped output files for tracking review history
- Error handling for file reading and API calls

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from the review process.

**Parameters:**
- `filename` (str): The file path to check

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Logic:**
- Excludes files containing "test" in the name or path
- Case-insensitive matching
- Handles both Unix and Windows path separators

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API planning.

**Parameters:**
- `text` (str): The source code content

**Returns:**
- `int`: Estimated token count (text length ÷ 4)

**Note:** This is a simplified estimation. For more accurate token counting, consider using the actual tokenizer for your model.

### `main()`

The primary function that orchestrates the entire review process.

**Key Steps:**
1. **Setup**: Loads environment variables and initializes Claude client
2. **File Discovery**: Recursively finds valid source files
3. **Token Batching**: Groups files into manageable chunks
4. **AI Processing**: Sends batches to Claude for review
5. **Output Generation**: Saves Markdown reports

## Configuration

### Environment Variables

```bash
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, has default
```

### Supported File Extensions

```python
valid_exts = (
    ".py", ".js", ".ts", ".tsx", ".jsx", 
    ".html", ".css", ".json", ".go", 
    ".java", ".yaml", ".yml"
)
```

## Usage

### Basic Usage

```bash
python claude_folder_review.py /path/to/your/codebase
```

### Default Folder

If no folder is specified, it defaults to `../137docs`:

```bash
python claude_folder_review.py
```

## Output Structure

The script generates files in the following structure:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_XX.md
```

Each batch file contains:
- Batch number and timestamp
- Claude's analysis focusing on:
  - Code organization
  - Bug patterns
  - Architecture weaknesses
  - Modularization suggestions

## Performance Considerations

- **Token Limit**: Each batch is capped at ~10,000 tokens
- **API Rate Limits**: No built-in rate limiting (consider adding delays for large codebases)
- **Memory Usage**: Files are read entirely into memory for processing

## Error Handling

The script includes error handling for:
- Missing or unreadable files
- Claude API failures
- Invalid folder paths

## Suggestions for Improvement

### 1. Enhanced Token Estimation
```python
# Consider using tiktoken for more accurate counting
import tiktoken

def accurate_token_count(text: str, model: str) -> int:
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))
```

### 2. Rate Limiting
```python
import time

# Add between API calls
time.sleep(1)  # 1 second delay
```

### 3. Configuration File
Consider adding a configuration file for:
- File extensions
- Exclusion patterns
- Batch sizes
- Output formats

### 4. Progress Tracking
```python
from tqdm import tqdm

# Add progress bars for better UX
for i, batch in enumerate(tqdm(batches, desc="Processing batches")):
    # ... processing logic
```

## Dependencies

```bash
pip install anthropic python-dotenv
```

## Notes

- Ensure your `ANTHROPIC_API_KEY` is properly set in your environment or `.env` file
- The script automatically creates the output directory if it doesn't exist
- Test files are excluded by default to focus on core application code
- Processing time depends on codebase size and API response times