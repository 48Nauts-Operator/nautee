<!-- Auto-generated by Claude on 2025-05-31 21:12 -->

# Claude Folder Review (Batched) Documentation

## Overview

The **Claude Folder Review (Batched)** script is a Python utility that performs automated code reviews of entire folder structures using Anthropic's Claude AI model. It intelligently processes large codebases by splitting files into manageable batches and generates comprehensive Markdown reviews for each batch.

## Purpose

This tool is designed to:
- **Analyze codebases at scale**: Review multiple source code files across various programming languages
- **Manage token limits**: Automatically batch files to stay within Claude's token constraints (~10k tokens per batch)
- **Generate structured reviews**: Output detailed Markdown documentation with insights on code quality, architecture, and improvement suggestions
- **Filter relevant files**: Focus on source code while excluding test files and unsupported formats

## Key Features

### Supported File Types
- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other languages**: `.go`, `.java`

### Intelligent Filtering
- Automatically excludes test files and directories
- Focuses on production source code for meaningful reviews

## Important Functions

### `is_excluded(filename: str) -> bool`
Determines whether a file should be excluded from the review process.

**Parameters:**
- `filename`: Path or name of the file to check

**Returns:**
- `True` if the file is a test file, `False` otherwise

**Detection patterns:**
- Files containing "test" in the name
- Files starting with "test_"
- Files in test directories

```python
# Examples of excluded files:
# - test_utils.py
# - /tests/unit_test.py
# - MyTest.java
```

### `estimate_tokens(text: str) -> int`
Provides a rough estimate of token count for batching purposes.

**Parameters:**
- `text`: Source code content as string

**Returns:**
- Estimated token count (uses 4:1 character-to-token ratio)

**Note:** This is an approximation used for batching logic, not precise tokenization.

## Configuration

### Environment Variables
The script requires the following environment variables (loaded via `.env` file):

- `ANTHROPIC_API_KEY`: Your Anthropic API key for Claude access
- `ANTHROPIC_MODEL`: (Optional) Claude model to use (defaults to "claude-sonnet-4-20250514")

### Command Line Usage

```bash
python claude_folder_review.py [folder_path]
```

**Parameters:**
- `folder_path`: (Optional) Path to the folder to review. Defaults to "../137docs"

## Workflow

1. **Setup Phase**
   - Load environment variables
   - Initialize Anthropic client
   - Create output directory structure

2. **File Discovery**
   - Recursively scan the target folder
   - Filter files by supported extensions
   - Exclude test files and directories

3. **Intelligent Batching**
   - Group files into batches under 10,000 tokens
   - Prevent token limit exceeded errors
   - Optimize API usage

4. **Review Generation**
   - Send each batch to Claude for analysis
   - Request structured Markdown reviews
   - Focus on code organization, bugs, architecture, and improvements

5. **Output Management**
   - Save each batch review as a separate Markdown file
   - Include timestamps and batch numbering
   - Store in `docs/folder_review/` directory

## Output Structure

Generated files follow this naming pattern:
```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

Each file contains:
- Batch header with number
- Timestamp of generation
- Detailed Claude analysis covering:
  - Code organization patterns
  - Potential bug patterns
  - Architecture weaknesses
  - Modularization suggestions

## Usage Examples

### Basic Usage
```bash
python claude_folder_review.py /path/to/my/project
```

### Using Default Path
```bash
python claude_folder_review.py
# Reviews ../137docs folder
```

## Notes and Suggestions

### Best Practices
- **API Key Security**: Store your Anthropic API key in a `.env` file, never in source code
- **Large Codebases**: The script handles large projects well due to intelligent batching
- **Review Workflow**: Use generated reviews as starting points for deeper code analysis

### Limitations
- **Token Estimation**: Uses approximate token counting; very large files might still cause issues
- **Language Detection**: Relies on file extensions rather than content analysis
- **Test Exclusion**: May occasionally exclude non-test files with "test" in the name

### Potential Improvements
- Add support for more file types
- Implement more sophisticated test file detection
- Add configuration file support for custom exclusion patterns
- Include file size limits to prevent processing extremely large files

## Error Handling

The script includes robust error handling for:
- File reading errors (permissions, encoding issues)
- API rate limiting and connection errors
- Missing or invalid environment variables
- Empty or invalid folder paths

Errors are logged with descriptive messages and emoji indicators for easy identification.