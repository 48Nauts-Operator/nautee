<!-- Auto-generated by Claude on 2025-06-22 07:19 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review system that uses Anthropic's Claude AI to analyze source code files in batches. The tool recursively scans a folder structure, groups files into manageable token-sized batches, and generates detailed markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverage Claude AI to provide insights on code organization, bug patterns, and architecture
- **Batch Processing**: Handle large codebases by splitting files into ~10k token chunks
- **Documentation Generation**: Create structured markdown reports for each batch of reviewed files
- **Scalable Analysis**: Process multiple file types across entire project directories

## Key Features

- Recursive folder scanning with file type filtering
- Intelligent token-based batching to optimize API usage
- Exclusion of test files to focus on production code
- Structured markdown output with timestamps
- Error handling and progress tracking

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from the review process.

**Parameters:**
- `filename` (str): The file path to evaluate

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Logic:**
- Excludes files containing "test" in the name or path
- Case-insensitive matching
- Handles both Unix and Windows path separators

```python
# Examples of excluded files:
# - test_utils.py
# - /tests/integration.py
# - MyTest.js
```

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API usage planning.

**Parameters:**
- `text` (str): Source code content

**Returns:**
- `int`: Estimated token count

**Note:** Uses a simple heuristic of 4 characters per token. This is an approximation and may vary based on actual tokenization.

### `main()`

The primary orchestration function that handles the entire review process.

**Key Steps:**
1. **Setup**: Load environment variables and initialize Claude client
2. **File Discovery**: Recursively scan for valid source files
3. **Token Batching**: Group files into batches under the token limit
4. **API Processing**: Send batches to Claude for review
5. **Output Generation**: Save structured markdown reports

## Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ANTHROPIC_API_KEY` | Required API key for Claude access | None |
| `ANTHROPIC_MODEL` | Claude model to use | `claude-sonnet-4-20250514` |

### Supported File Types

The script processes files with the following extensions:
- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other Languages**: `.go`, `.java`

### Configuration Constants

```python
MAX_TOKENS = 10000      # Maximum tokens per batch
output_root = "docs/folder_review"  # Output directory
```

## Usage

### Basic Usage

```bash
python script.py [folder_path]
```

### Examples

```bash
# Review current directory
python claude_folder_review.py .

# Review specific project folder
python claude_folder_review.py /path/to/project

# Use default folder (../137docs)
python claude_folder_review.py
```

## Output Structure

The script generates numbered markdown files in the `docs/folder_review/` directory:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

Each file contains:
- Batch number and timestamp
- Claude's analysis focusing on:
  - Code organization
  - Bug patterns
  - Architecture weaknesses
  - Modularization suggestions

## Dependencies

```python
# Required packages
anthropic      # Claude AI API client
python-dotenv  # Environment variable management
```

Install dependencies:
```bash
pip install anthropic python-dotenv
```

## Error Handling

The script includes robust error handling for:
- **File Reading Errors**: Skips unreadable files with error messages
- **API Errors**: Continues processing remaining batches if one fails
- **Missing Files**: Graceful exit if no valid files are found

## Performance Considerations

- **Token Estimation**: Uses approximation for batching; actual API usage may vary
- **Rate Limiting**: No built-in rate limiting; consider API usage limits
- **Memory Usage**: Loads entire files into memory; may need optimization for very large files

## Suggestions for Improvement

1. **Rate Limiting**: Add delays between API calls to respect rate limits
2. **Concurrent Processing**: Implement async processing for faster execution
3. **Better Token Estimation**: Use actual tokenizer for more accurate batching
4. **Configuration File**: Move settings to external config file
5. **Resume Capability**: Add ability to resume interrupted batch processing
6. **File Size Limits**: Add maximum file size limits to prevent memory issues

## Security Notes

- Store API keys in `.env` file, never in source code
- Add `.env` to `.gitignore` to prevent accidental commits
- Consider using environment-specific API keys for different deployment stages