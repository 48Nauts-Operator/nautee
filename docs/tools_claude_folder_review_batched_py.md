<!-- Auto-generated by Claude on 2025-06-02 05:21 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides automated code review functionality using Anthropic's Claude AI model. It recursively scans a folder for source code files, intelligently batches them based on token limits, and generates comprehensive markdown reviews using Claude's analysis capabilities.

## Purpose

- **Automated Code Review**: Leverage AI to review large codebases systematically
- **Batch Processing**: Handle large projects by splitting files into manageable chunks
- **Documentation Generation**: Create structured markdown reports for each batch
- **Multi-language Support**: Review various programming languages and configuration files

## Key Features

- ðŸ” **Smart File Discovery**: Recursively finds source code files with configurable extensions
- ðŸ“¦ **Token-based Batching**: Automatically splits files into ~10k token chunks to respect API limits
- ðŸš« **Test File Filtering**: Excludes test files from review by default
- ðŸ“ **Markdown Output**: Generates well-formatted review documentation
- âš¡ **Progress Tracking**: Real-time feedback on batch processing status

## Important Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from review based on naming patterns.

**Parameters:**
- `filename`: Full path or name of the file to check

**Returns:**
- `True` if the file appears to be a test file, `False` otherwise

**Example:**
```python
is_excluded("test_utils.py")        # Returns True
is_excluded("src/test/helper.js")   # Returns True
is_excluded("main.py")              # Returns False
```

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API rate limiting.

**Parameters:**
- `text`: Source code content to analyze

**Returns:**
- Estimated token count (uses 4:1 character-to-token ratio)

**Note:** This is a simplified estimation. For production use, consider using tiktoken or similar libraries for more accurate token counting.

## Configuration

### Environment Variables

Create a `.env` file with the following variables:

```bash
ANTHROPIC_API_KEY=your_claude_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, defaults to this model
```

### Supported File Extensions

The script processes files with these extensions:
- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other**: `.go`, `.java`

## Usage

### Basic Usage
```bash
python claude_folder_review.py /path/to/your/project
```

### Using Default Folder
```bash
python claude_folder_review.py
# Uses ../137docs as default folder
```

### Output Structure
```
docs/folder_review/
â”œâ”€â”€ folder_review_batch_01.md
â”œâ”€â”€ folder_review_batch_02.md
â””â”€â”€ folder_review_batch_03.md
```

## Sample Output

Each generated markdown file includes:

```markdown
# ðŸ“¦ Folder Review Batch 1

_Last updated: 2024-01-15 14:30_

## Code Organization
- Well-structured module hierarchy
- Clear separation of concerns

## Bug Patterns
- Missing error handling in file operations
- Potential race conditions in async operations

## Architecture Weaknesses
- Tight coupling between data and presentation layers
- Limited abstraction for external API calls

## Suggestions
- Implement dependency injection
- Add comprehensive logging
- Consider using design patterns for better maintainability
```

## Dependencies

Install required packages:

```bash
pip install anthropic python-dotenv
```

## Best Practices & Suggestions

### Performance Optimization
- **Token Management**: The 10,000 token limit balances API efficiency with comprehensive analysis
- **File Filtering**: Customize `is_excluded()` to skip irrelevant files (logs, cache, etc.)
- **Batch Size**: Consider adjusting `MAX_TOKENS` based on your needs and API rate limits

### Error Handling
- The script continues processing even if individual files fail to read
- API errors are logged but don't stop the entire process
- Consider adding retry logic for transient API failures

### Customization Ideas
```python
# Add more file types
valid_exts = (".py", ".rb", ".php", ".cpp", ".h")

# Custom exclusion patterns
def is_excluded(filename: str) -> bool:
    exclude_patterns = ["test", "node_modules", ".git", "build", "dist"]
    return any(pattern in filename.lower() for pattern in exclude_patterns)
```

### Security Considerations
- Store API keys in environment variables, never in code
- Be mindful of sending proprietary code to external APIs
- Consider data retention policies of the AI service

## Limitations

- **Token Estimation**: Uses simplified character-based estimation
- **Language Detection**: Doesn't validate file content matches extension
- **API Rate Limits**: No built-in rate limiting or retry logic
- **Memory Usage**: Loads entire files into memory (may be problematic for very large files)

## Future Enhancements

- Add support for custom review prompts
- Implement more sophisticated token counting
- Add configuration file support (YAML/JSON)
- Include code metrics and complexity analysis
- Support for incremental reviews (only changed files)