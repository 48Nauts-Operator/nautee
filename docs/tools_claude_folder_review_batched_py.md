<!-- Auto-generated by Claude on 2025-06-08 06:28 -->

# Claude Folder Review (Batched) - Documentation

## Overview

This Python script provides an automated code review solution that uses Claude AI to analyze source code files in batches. It recursively scans a folder structure, groups files into manageable token-sized batches, and generates comprehensive markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverage Claude AI to perform intelligent code analysis
- **Batch Processing**: Handle large codebases by splitting them into ~10k token chunks
- **Documentation Generation**: Create structured markdown reports for review insights
- **Scalable Analysis**: Process multiple file types across entire project directories

## Key Features

- Recursive folder scanning with file type filtering
- Smart token estimation and batching
- Test file exclusion
- Error handling and progress tracking
- Timestamped markdown output

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from analysis based on naming patterns.

**Parameters:**
- `filename` (str): The file path to evaluate

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Exclusion Criteria:**
- Files containing "test" in the name (case-insensitive)
- Files starting with "test_"
- Files in directories containing "test"

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for Claude API usage planning.

**Parameters:**
- `text` (str): The source code content to analyze

**Returns:**
- `int`: Estimated token count (uses 4:1 character-to-token ratio)

### `main()`

The primary execution function that orchestrates the entire review process.

**Process Flow:**
1. **Setup**: Load environment variables and initialize Claude client
2. **File Discovery**: Scan directory for valid source files
3. **Batching**: Group files by estimated token count
4. **API Calls**: Send batches to Claude for analysis
5. **Output**: Generate timestamped markdown reports

## Configuration

### Environment Variables

Create a `.env` file with the following variables:

```bash
ANTHROPIC_API_KEY=your_claude_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, defaults to this model
```

### Supported File Types

The script processes files with these extensions:
- **Python**: `.py`
- **JavaScript/TypeScript**: `.js`, `.ts`, `.tsx`, `.jsx`
- **Web**: `.html`, `.css`
- **Data**: `.json`, `.yaml`, `.yml`
- **Other Languages**: `.go`, `.java`

## Usage

### Basic Usage

```bash
python claude_folder_review.py [folder_path]
```

### Examples

```bash
# Review current directory's parent folder
python claude_folder_review.py ../my_project

# Review specific folder
python claude_folder_review.py /path/to/codebase

# Use default folder (../137docs)
python claude_folder_review.py
```

## Output Structure

The script generates markdown files in the `docs/folder_review/` directory:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

Each file contains:
- Batch number and timestamp
- Code organization analysis
- Bug pattern identification
- Architecture recommendations
- Modularization suggestions

## Dependencies

```bash
pip install anthropic python-dotenv
```

## Configuration Options

| Variable | Default | Description |
|----------|---------|-------------|
| `MAX_TOKENS` | 10000 | Maximum tokens per batch |
| `output_root` | `docs/folder_review` | Output directory |
| `folder` | `../137docs` | Default input folder |

## Notes and Suggestions

### Performance Considerations
- **Token Limits**: Each batch is capped at ~10k tokens to stay within Claude's limits
- **Rate Limiting**: Consider adding delays between API calls for large codebases
- **Cost Management**: Monitor API usage, especially for large projects

### Customization Opportunities
- **File Filtering**: Modify `valid_exts` to include additional file types
- **Review Focus**: Adjust the Claude prompt to emphasize specific analysis areas
- **Output Format**: Customize the markdown template for different reporting needs

### Error Handling
- Files that can't be read are skipped with error logging
- API failures are caught and reported per batch
- The script continues processing remaining batches if one fails

### Best Practices
- Review the generated markdown files to understand code patterns
- Use batch-specific insights to prioritize refactoring efforts
- Consider running reviews periodically on actively developed codebases

## Troubleshooting

### Common Issues
- **No files found**: Check file extensions and exclusion patterns
- **API errors**: Verify ANTHROPIC_API_KEY is set correctly
- **Permission errors**: Ensure read access to source folders and write access to output directory

### Debug Tips
- Check console output for file discovery and processing status
- Verify `.env` file is in the same directory as the script
- Test with a small folder first to validate configuration