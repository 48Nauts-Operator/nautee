<!-- Auto-generated by Claude on 2025-06-01 21:17 -->

# Claude Folder Review (Batched) Documentation

## Overview

This script provides an automated code review solution that recursively analyzes source code files from a folder using Anthropic's Claude AI model. The tool intelligently batches files based on token limits and generates comprehensive markdown documentation with code review insights.

## Purpose

- **Automated Code Review**: Leverages Claude AI to provide senior-level code review insights
- **Batch Processing**: Handles large codebases by splitting files into manageable chunks (~10k tokens each)
- **Documentation Generation**: Creates structured markdown reports for each batch of reviewed files
- **Multi-language Support**: Works with various programming languages and file types

## Key Features

- Token-aware batching to optimize API usage
- Automatic exclusion of test files
- Comprehensive file type support
- Error handling and progress tracking
- Timestamped output files

## Functions

### `is_excluded(filename: str) -> bool`

**Purpose**: Filters out test files from the review process.

**Parameters**:
- `filename` (str): The file path to check

**Returns**: 
- `bool`: True if the file should be excluded (contains "test" patterns)

**Logic**:
- Checks for "test" keyword in filename (case-insensitive)
- Identifies test files starting with "test_"
- Detects test directories in the path

```python
# Examples of excluded files:
# - test_example.py
# - /tests/unit_test.js
# - example_test.go
```

### `estimate_tokens(text: str) -> int`

**Purpose**: Provides a rough estimation of token count for API usage planning.

**Parameters**:
- `text` (str): Source code content

**Returns**:
- `int`: Estimated token count (using 4 characters ≈ 1 token rule)

**Note**: This is a simplified estimation. Actual token counts may vary depending on the model's tokenization.

## Main Workflow

### 1. Setup Phase
- Loads environment variables (API key, model selection)
- Initializes Anthropic client
- Sets up output directory structure
- Defines supported file extensions

### 2. File Discovery
- Recursively walks through the target folder
- Filters files by supported extensions
- Excludes test files using `is_excluded()`
- Reports the total number of discoverable files

### 3. Token Batching
- Groups files into batches with ~10,000 token limit
- Formats each file with markdown code blocks
- Tracks cumulative token count per batch
- Handles file reading errors gracefully

### 4. AI Review Processing
- Sends each batch to Claude with structured prompts
- Focuses on:
  - Code organization
  - Bug patterns  
  - Architecture weaknesses
  - Modularization suggestions
- Generates timestamped markdown reports

## Configuration

### Environment Variables

```bash
# Required
ANTHROPIC_API_KEY=your_api_key_here

# Optional (defaults to claude-sonnet-4-20250514)
ANTHROPIC_MODEL=claude-sonnet-4-20250514
```

### Supported File Extensions

```python
valid_exts = (
    ".py", ".js", ".ts", ".tsx", ".jsx", 
    ".html", ".css", ".json", ".go", 
    ".java", ".yaml", ".yml"
)
```

## Usage

### Basic Usage
```bash
python claude_folder_review.py /path/to/source/folder
```

### Default Folder
```bash
python claude_folder_review.py
# Uses "../137docs" as default folder
```

## Output Structure

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_XX.md
```

Each output file contains:
- Batch number and timestamp
- Detailed code review insights
- Architecture recommendations
- Bug pattern identification

## Error Handling

- **File Reading Errors**: Continues processing other files, logs errors
- **API Errors**: Reports Claude API issues per batch, continues with remaining batches
- **Missing Files**: Exits gracefully with informative error messages

## Performance Considerations

- **Token Limits**: Batches are capped at ~10k tokens to optimize API performance
- **Rate Limiting**: Consider adding delays between API calls for large codebases
- **Memory Usage**: Files are read individually to minimize memory footprint

## Suggestions for Enhancement

### 1. **Rate Limiting**
```python
import time
# Add between API calls
time.sleep(1)  # 1 second delay
```

### 2. **Configuration File**
Consider adding a config file for:
- Custom file extensions
- Exclusion patterns
- Token limits
- Output formatting preferences

### 3. **Parallel Processing**
For large codebases, implement async processing:
```python
import asyncio
# Process multiple batches concurrently
```

### 4. **Progress Tracking**
Add progress bars for better user experience:
```python
from tqdm import tqdm
# Show progress during file processing
```

## Dependencies

```python
pip install anthropic python-dotenv
```

## Notes

- Ensure your Anthropic API key has sufficient credits for large codebases
- Review token estimation accuracy for your specific use case
- Consider implementing retry logic for transient API failures
- The script assumes UTF-8 encoding for all source files