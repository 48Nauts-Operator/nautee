<!-- Auto-generated by Claude on 2025-06-22 03:25 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script provides an automated code review system that uses Anthropic's Claude AI to analyze source code files in batches. The tool recursively scans a folder for source code files, organizes them into token-limited batches, and generates comprehensive Markdown reviews for each batch.

## Purpose

- **Automated Code Review**: Leverage Claude AI to perform comprehensive code reviews
- **Batch Processing**: Handle large codebases by splitting files into manageable chunks
- **Documentation Generation**: Create structured Markdown reports for review insights
- **Token Management**: Automatically manage API token limits to optimize cost and performance

## Key Features

- Recursive folder scanning for multiple file types
- Automatic exclusion of test files
- Token estimation and intelligent batching
- Markdown report generation with timestamps
- Error handling and progress tracking

## Functions

### `is_excluded(filename: str) -> bool`

Determines whether a file should be excluded from the review process.

**Parameters:**
- `filename` (str): The file path to check

**Returns:**
- `bool`: True if the file should be excluded (test files), False otherwise

**Exclusion Criteria:**
- Files containing "test" in the name (case-insensitive)
- Files starting with "test_"
- Files in directories containing "test"

### `estimate_tokens(text: str) -> int`

Provides a rough estimation of token count for API usage planning.

**Parameters:**
- `text` (str): The source code content

**Returns:**
- `int`: Estimated token count (using 4 characters per token approximation)

### `main()`

The primary function that orchestrates the entire review process:

1. **Setup Phase**: Loads environment variables and initializes Claude client
2. **File Discovery**: Recursively finds valid source code files
3. **Batch Creation**: Groups files into token-limited batches
4. **Review Generation**: Processes each batch through Claude API
5. **Output**: Saves individual Markdown reports for each batch

## Configuration

### Environment Variables

```bash
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, defaults to this model
```

### Supported File Extensions

```python
valid_exts = (".py", ".js", ".ts", ".tsx", ".jsx", ".html", ".css", ".json", ".go", ".java", ".yaml", ".yml")
```

## Usage

### Command Line

```bash
# Review files in a specific folder
python claude_folder_review.py /path/to/your/project

# Use default folder (../137docs)
python claude_folder_review.py
```

### Output Structure

```
docs/folder_review/
â”œâ”€â”€ folder_review_batch_01.md
â”œâ”€â”€ folder_review_batch_02.md
â””â”€â”€ folder_review_batch_03.md
```

## Configuration Options

| Setting | Default Value | Description |
|---------|---------------|-------------|
| `MAX_TOKENS` | 10,000 | Maximum tokens per batch |
| `output_root` | `docs/folder_review` | Output directory for reviews |
| `model` | `claude-sonnet-4-20250514` | Claude model to use |

## Review Focus Areas

The generated reviews focus on:

- **Code Organization**: Structure and modularity assessment
- **Bug Patterns**: Identification of common issues and anti-patterns
- **Architecture Weaknesses**: Structural problems and design flaws
- **Improvement Suggestions**: Recommendations for modularization and clarity

## Error Handling

The script includes robust error handling for:

- Missing or invalid API keys
- File reading errors (logs errors but continues processing)
- Claude API errors (reports but continues with remaining batches)
- Empty folder scenarios

## Performance Considerations

### Token Management
- Files are batched to stay within the 10,000 token limit
- Token estimation helps optimize API usage costs
- Processing time is tracked and reported

### Rate Limiting
- Sequential batch processing prevents API rate limit issues
- Consider adding delays between requests for very large codebases

## Dependencies

```python
anthropic>=0.3.0
python-dotenv>=0.19.0
```

## Installation

```bash
pip install anthropic python-dotenv
```

## Notes and Suggestions

### Best Practices

1. **API Key Security**: Store your Anthropic API key in a `.env` file, never commit it to version control
2. **Large Codebases**: For very large projects, consider running during off-peak hours due to processing time
3. **Review Quality**: The tool works best on well-structured codebases with clear file organization

### Potential Improvements

- Add support for custom file extension filters
- Implement parallel batch processing for faster execution
- Add configuration file support for different project types
- Include code metrics and complexity analysis
- Add integration with popular code review platforms

### Limitations

- Token estimation is approximate and may not perfectly match Claude's actual token counting
- Test file exclusion is based on naming conventions and may miss some test files
- Large individual files may exceed token limits and need manual splitting

## Example Output

Each generated review file includes:

```markdown
# ðŸ“¦ Folder Review Batch 1

_Last updated: 2024-01-15 14:30_

## Code Organization
The codebase shows good separation of concerns...

## Bug Patterns
Several potential issues were identified...

## Architecture Recommendations
Consider implementing the following improvements...
```