<!-- Auto-generated by Claude on 2025-06-02 03:21 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script performs automated code reviews of entire folders using Anthropic's Claude AI in batches. It intelligently splits large codebases into manageable chunks and generates detailed markdown reviews for analysis and improvement suggestions.

## Purpose

- **Automated Code Review**: Leverage Claude AI to review source code files at scale
- **Batch Processing**: Handle large codebases by splitting them into ~10k token chunks
- **Documentation Generation**: Create structured markdown reports for each batch
- **Codebase Analysis**: Identify patterns, bugs, and architectural improvements

## Key Features

- Recursive folder scanning for source files
- Intelligent file filtering (excludes test files)
- Token-based batching to respect API limits
- Support for multiple programming languages
- Structured markdown output with timestamps

## Functions

### `is_excluded(filename: str) -> bool`

Filters out test files from the review process.

**Parameters:**
- `filename`: Path or name of the file to check

**Returns:**
- `bool`: True if file should be excluded (test files)

**Logic:**
- Excludes files containing "test" in filename
- Excludes files starting with "test_"
- Excludes files in test directories

```python
# Examples of excluded files:
# - test_something.py
# - /tests/unit_test.js
# - TestRunner.java
```

### `estimate_tokens(text: str) -> int`

Provides a rough estimate of token count for batching purposes.

**Parameters:**
- `text`: Source code content

**Returns:**
- `int`: Estimated token count (text length ÷ 4)

**Note:** This is a simplified estimation. Actual token counts may vary.

## Main Workflow

### 1. Setup and Configuration

```python
# Environment variables loaded
ANTHROPIC_API_KEY  # Required: Your Claude API key
ANTHROPIC_MODEL    # Optional: Defaults to "claude-sonnet-4-20250514"
```

### 2. File Discovery

- Scans target folder recursively
- Filters by supported extensions
- Excludes test files automatically

**Supported File Extensions:**
- `.py`, `.js`, `.ts`, `.tsx`, `.jsx`
- `.html`, `.css`, `.json`
- `.go`, `.java`
- `.yaml`, `.yml`

### 3. Intelligent Batching

- **Token Limit**: 10,000 tokens per batch
- **Smart Grouping**: Files are grouped to maximize batch size without exceeding limits
- **Overflow Handling**: Large files that exceed limits start new batches

### 4. Claude AI Review

Each batch is sent to Claude with a structured prompt focusing on:
- Code organization and structure
- Bug patterns and potential issues
- Architecture weaknesses
- Modularization suggestions
- Code clarity improvements

### 5. Output Generation

- Creates individual markdown files per batch
- Includes timestamps and batch numbering
- Saves to `docs/folder_review/` directory

## Usage

### Basic Usage

```bash
python claude_folder_review.py /path/to/your/codebase
```

### Default Folder

```bash
python claude_folder_review.py
# Uses "../137docs" as default folder
```

### Output Structure

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

## Configuration

### Environment Variables

Create a `.env` file with:

```bash
ANTHROPIC_API_KEY=your_claude_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional
```

### Customization Options

You can modify these constants in the script:

```python
MAX_TOKENS = 10000           # Tokens per batch
valid_exts = (...)           # Supported file extensions
output_root = "docs/folder_review"  # Output directory
```

## Error Handling

- **File Reading Errors**: Continues processing other files, logs errors
- **API Errors**: Reports failed batches, continues with remaining batches
- **Empty Folders**: Exits gracefully with informative message

## Performance Considerations

- **API Rate Limits**: Processes batches sequentially to respect Claude API limits
- **Memory Usage**: Loads files individually, not all at once
- **Token Estimation**: Uses approximation for speed (actual usage may vary)

## Notes and Suggestions

### Best Practices

1. **Review Output**: Always review generated markdown files for accuracy
2. **API Costs**: Monitor your Anthropic API usage, especially for large codebases
3. **Batch Size**: Adjust `MAX_TOKENS` based on your needs and API limits

### Potential Improvements

- Add support for additional file types
- Implement more accurate token counting
- Add parallel processing with rate limiting
- Include file metrics (lines of code, complexity)
- Add summary report across all batches

### Limitations

- Token estimation is approximate
- No syntax validation before sending to Claude
- Sequential processing (no parallelization)
- Limited to text-based source files

## Dependencies

```bash
pip install anthropic python-dotenv
```

## Example Output

Each generated markdown file includes:
- Batch header with timestamp
- Code organization analysis
- Bug pattern identification
- Architecture recommendations
- Specific improvement suggestions

This tool is ideal for getting AI-powered insights into large codebases, identifying technical debt, and planning refactoring efforts.