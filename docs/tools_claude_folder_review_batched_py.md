<!-- Auto-generated by Claude on 2025-06-22 05:19 -->

# Claude Folder Review (Batched) Documentation

## Overview

This Python script is an automated code review tool that leverages Claude AI to analyze source code files in batches. The tool recursively scans a folder structure, processes code files, and generates comprehensive markdown reviews focusing on code organization, bug patterns, and architectural improvements.

## Purpose

- **Automated Code Review**: Provides AI-powered analysis of codebases without manual intervention
- **Batch Processing**: Handles large codebases by splitting files into manageable token chunks
- **Documentation Generation**: Creates structured markdown reports for easy reading and sharing
- **Multi-language Support**: Supports various programming languages and file formats

## Key Features

### File Discovery & Filtering
- Recursively scans directories for source code files
- Automatically excludes test files to focus on production code
- Supports multiple file extensions (Python, JavaScript, TypeScript, HTML, CSS, etc.)

### Token Management
- Estimates token count to stay within Claude's API limits
- Batches files into ~10,000 token chunks for optimal processing
- Prevents API errors due to context length restrictions

### Review Generation
- Generates individual markdown files for each batch
- Focuses on code organization, bug patterns, and architecture
- Timestamps all reviews for tracking purposes

## Important Functions

### `is_excluded(filename: str) -> bool`
Filters out test files from the review process.

**Parameters:**
- `filename`: File path to evaluate

**Returns:**
- `bool`: True if file should be excluded (contains "test" patterns)

**Example Usage:**
```python
if not is_excluded(file_path):
    files.append(file_path)
```

### `estimate_tokens(text: str) -> int`
Estimates token count for API rate limiting.

**Parameters:**
- `text`: Source code content

**Returns:**
- `int`: Estimated token count (using 4 characters per token ratio)

**Example Usage:**
```python
token_count = estimate_tokens(source_code)
if current_tokens + token_count > MAX_TOKENS:
    # Start new batch
```

### `main()`
The primary function that orchestrates the entire review process:

1. **Setup Phase**: Loads environment variables and initializes Claude client
2. **File Discovery**: Scans directory structure for valid source files
3. **Batching**: Groups files into token-appropriate batches
4. **Review Generation**: Processes each batch through Claude API
5. **Output**: Saves markdown reviews to organized file structure

## Configuration

### Environment Variables
```bash
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # Optional, has default
```

### Supported File Extensions
```python
valid_exts = (
    ".py", ".js", ".ts", ".tsx", ".jsx", 
    ".html", ".css", ".json", ".go", 
    ".java", ".yaml", ".yml"
)
```

## Usage

### Basic Usage
```bash
python claude_folder_review.py /path/to/your/codebase
```

### Default Behavior
```bash
python claude_folder_review.py
# Uses default folder: "../137docs"
```

## Output Structure

The script generates organized output in the `docs/folder_review/` directory:

```
docs/folder_review/
├── folder_review_batch_01.md
├── folder_review_batch_02.md
└── folder_review_batch_03.md
```

Each batch file contains:
- Batch number and timestamp
- Detailed code analysis
- Architectural recommendations
- Bug pattern identification

## Configuration Notes

### Token Limits
- **Default Batch Size**: 10,000 tokens
- **API Response Limit**: 2,000 tokens
- **Estimation Method**: 4 characters per token (approximate)

### Rate Limiting
The script processes batches sequentially to avoid API rate limits. For large codebases, consider adding delays between requests if needed.

## Error Handling

The script includes robust error handling for:
- **File Reading Errors**: Continues processing other files if individual files fail
- **API Errors**: Reports Claude API issues while continuing with remaining batches
- **Missing Files**: Validates file existence before processing

## Suggestions for Improvement

### Performance Enhancements
- Add configurable delay between API calls for rate limit management
- Implement parallel processing for file reading (not API calls)
- Add progress bars for better user experience

### Feature Additions
- **Language Detection**: Automatically detect file types for better prompting
- **Custom Exclusions**: Allow user-defined exclusion patterns via config file
- **Summary Report**: Generate an overall summary across all batches
- **Incremental Updates**: Only process files changed since last review

### Error Recovery
- **Retry Logic**: Implement exponential backoff for API failures
- **Resume Capability**: Allow resuming from failed batches
- **Validation**: Add content validation before API submission

## Dependencies

```python
anthropic>=0.3.0
python-dotenv>=0.19.0
```

## Security Considerations

- Store API keys in `.env` file (never commit to version control)
- Consider token usage costs when processing large codebases
- Review generated content before sharing (may contain sensitive code patterns)