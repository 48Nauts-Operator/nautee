<!-- Auto-generated by Claude on 2025-06-21 22:18 -->

# Claude Review Tool Documentation

## Overview

The Claude Review Tool is a Python script that automates code reviews using Anthropic's Claude AI. It can analyze either specific source files or Git diffs, providing structured feedback in Markdown format. The tool is designed to integrate into development workflows for automated code quality assessment.

## Purpose

- **Automated Code Review**: Leverage Claude AI to perform consistent code reviews
- **Flexible Input**: Support both individual file analysis and Git diff reviews
- **Structured Output**: Generate readable Markdown reports for easy consumption
- **Development Integration**: Seamlessly integrate into CI/CD pipelines or local development workflows

## Features

- Two review modes: manual file review and Git diff analysis
- Markdown-formatted output with timestamps
- Error handling for missing files and Git operations
- Configurable Claude model selection
- Automatic output directory creation

## Requirements

- Python 3.6+
- Required packages:
  - `anthropic`
  - `python-dotenv`
- Environment variables:
  - `ANTHROPIC_API_KEY` (required)
  - `ANTHROPIC_MODEL` (optional, defaults to "claude-sonnet-4-20250514")

## Installation

```bash
pip install anthropic python-dotenv
```

Create a `.env` file in your project root:
```env
ANTHROPIC_API_KEY=your_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514  # optional
```

## Usage

### Mode 1: Review Specific Files
```bash
python claude_review.py file1.py file2.py file3.py
```

### Mode 2: Review Git Diff
```bash
python claude_review.py
```

## Functions

### `load_code(file_paths)`

Combines multiple source files into a single Markdown-formatted string for review.

**Parameters:**
- `file_paths` (list): List of file paths to process

**Returns:**
- `str`: Markdown-formatted string containing all file contents

**Features:**
- Skips missing files with warning messages
- Formats each file with proper Markdown code blocks
- Assumes Python syntax highlighting (hardcoded)

### `get_git_diff()`

Retrieves Git diff output with fallback strategies for different repository states.

**Returns:**
- `str`: Git diff content or empty string if unavailable

**Fallback Strategy:**
1. First attempts: `git diff origin/main...HEAD`
2. If failed, tries: `git diff HEAD^`
3. Returns empty string if both fail

### `main()`

Primary execution function that orchestrates the entire review process.

**Process Flow:**
1. Load environment variables and initialize Claude client
2. Determine review mode based on command-line arguments
3. Prepare appropriate prompt for Claude
4. Make API call and process response
5. Save formatted output to `docs/claude_review.md`

## Output

The tool generates a Markdown file at `docs/claude_review.md` with:
- Header with brain emoji and timestamp
- Structured feedback focusing on:
  - Bugs or logic issues
  - Code clarity
  - Suggested improvements
  - Style consistency

## Error Handling

- **Missing Files**: Warns and skips non-existent files
- **Git Errors**: Graceful fallback between different diff strategies
- **API Errors**: Catches and reports Claude API failures
- **No Diff Available**: Creates stub review when no changes detected

## Notes and Suggestions

### ‚ö†Ô∏è Current Limitations

1. **Hardcoded Language**: The `load_code()` function assumes Python syntax highlighting
2. **File Extension Assumption**: No automatic language detection
3. **Token Limits**: Fixed at 1500 tokens maximum response

### üîß Suggested Improvements

1. **Dynamic Language Detection**:
   ```python
   def detect_language(file_path):
       ext_map = {'.py': 'python', '.js': 'javascript', '.java': 'java'}
       _, ext = os.path.splitext(file_path)
       return ext_map.get(ext, 'text')
   ```

2. **Configurable Token Limits**:
   ```python
   max_tokens = int(os.getenv("MAX_TOKENS", "1500"))
   ```

3. **Enhanced Error Logging**:
   ```python
   import logging
   logging.basicConfig(level=logging.INFO)
   ```

4. **Custom Output Paths**:
   ```python
   output_path = os.getenv("REVIEW_OUTPUT_PATH", "docs/claude_review.md")
   ```

### üí° Best Practices

- **Environment Security**: Never commit `.env` files with API keys
- **Git Integration**: Consider running as a pre-commit hook
- **Batch Processing**: For large codebases, consider splitting into smaller chunks
- **Review History**: Implement versioning for review outputs

### üöÄ Integration Examples

**Pre-commit Hook**:
```bash
#!/bin/sh
python claude_review.py $(git diff --cached --name-only --diff-filter=ACM | grep '\.py$')
```

**CI/CD Pipeline**:
```yaml
- name: Code Review
  run: python claude_review.py
- name: Upload Review
  uses: actions/upload-artifact@v2
  with:
    name: code-review
    path: docs/claude_review.md
```